{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3a7962-cd9d-4e7c-bc82-825e2e48a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers, processors, Regex\n",
    "from tokenizers.pre_tokenizers import Whitespace, Punctuation, Sequence, PreTokenizer, Split\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b1af8b-17dc-4feb-836a-70f3e20141dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "\n",
    "DATA_FILES = [\n",
    "    \"../data/sbd_adjudicatory_dec/data_set/intellectual_property.json\",\n",
    "    \"../data/sbd_adjudicatory_dec/data_set/bva.json\",\n",
    "    \"../data/sbd_adjudicatory_dec/data_set/scotus.json\",\n",
    "]\n",
    "\n",
    "VAL_DATA_FILE = [\n",
    "    \"../data/sbd_adjudicatory_dec/data_set/cyber_crime.json\",\n",
    "]\n",
    "\n",
    "CONTEXT_WINDOW = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73c7201-2050-4683-ba29-74d63484df1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set((3,2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d342a87-0d7d-4a45-a483-6a3281e0013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts_from_json_files(file_paths):\n",
    "    texts = []\n",
    "    files = []\n",
    "    keys = []\n",
    "    all_ends = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            for key in data:\n",
    "                if 'text' in data[key]:\n",
    "                    texts.append(data[key]['text'])\n",
    "                    files.append(file_path)\n",
    "                    keys.append(key)\n",
    "\n",
    "                file_ends = []\n",
    "                for annotation in data[key]['annotations']:\n",
    "                    file_ends.append(annotation['end'])\n",
    "                all_ends.append(sorted(list(set(file_ends))))\n",
    "    return texts, all_ends, files, keys\n",
    "\n",
    "def label_tokens(offsets, ends):\n",
    "    ends_idx = 0\n",
    "    labels = []\n",
    "    encoded_end_idxes = []\n",
    "\n",
    "    for offsets_idx, offset in enumerate(offsets):\n",
    "        left, right = offset\n",
    "        if (ends_idx < len(ends)) and (left <= (ends[ends_idx]-1) < right):\n",
    "            labels.append(True)\n",
    "            encoded_end_idxes.append(offsets_idx)\n",
    "            ends_idx += 1\n",
    "        else:\n",
    "            labels.append(False)\n",
    "\n",
    "    return encoded_end_idxes, labels\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, ends, tokenizer, padding=CONTEXT_WINDOW, device='cpu'):\n",
    "        self.texts = texts\n",
    "        self.ends = ends\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.encoded_texts, self.labels = self._encode(texts, ends, tokenizer, padding)\n",
    "        self.window_ids, self.windows_labels = self._extract_contexts(\n",
    "            self.encoded_texts,\n",
    "            self.labels\n",
    "        )\n",
    "\n",
    "    def _encode(self, train_texts, ends, tokenizer, padding=CONTEXT_WINDOW):\n",
    "        encoded_texts = []\n",
    "        labels = []\n",
    "        pad_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "        for i, text in enumerate(train_texts):\n",
    "            encoded = tokenizer.encode(text)\n",
    "            encoded.pad(len(encoded) + padding, direction=\"left\", pad_id=pad_id)\n",
    "            encoded.pad(len(encoded) + padding, direction=\"right\", pad_id=pad_id)\n",
    "            encoded_texts.append(encoded)\n",
    "            _, labeled_tokens = label_tokens(encoded.offsets, ends[i])\n",
    "            labels.append(labeled_tokens)\n",
    "\n",
    "        return encoded_texts, labels\n",
    "\n",
    "    def _is_end_of_line(self, tokens, i):\n",
    "        num_tokens = len(tokens)\n",
    "        if i >= num_tokens:\n",
    "            raise ValueError()\n",
    "        elif (i < (num_tokens - 1)) and (tokens[i] != \"\\n\") and (tokens[i+1] == \"\\n\"):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _extract_contexts(\n",
    "        self,\n",
    "        encoded_texts,\n",
    "        labels,\n",
    "        target_tokens=['.', '\"', ']', ')', ':', '\"', \"'\", '*', '>', ';'],\n",
    "        # target_tokens=['.'],\n",
    "        context_size=CONTEXT_WINDOW\n",
    "    ):\n",
    "        window_ids = []\n",
    "        window_labels = []\n",
    "        for i, encoded_text in enumerate(encoded_texts):\n",
    "            tokens = encoded_text.tokens\n",
    "            num_tokens = len(tokens)\n",
    "            for j in range(num_tokens):\n",
    "                token = tokens[j]\n",
    "                if (token in target_tokens) or self._is_end_of_line(tokens, j) or labels[i][j]:\n",
    "                    start = max(0, j - context_size)\n",
    "                    end = min(len(encoded_text), j + context_size + 1)\n",
    "                    window_ids.append(encoded_text.ids[start:end])\n",
    "                    # window_tokens.append(encoded_text.tokens[start:end])\n",
    "                    window_labels.append(labels[i][j])\n",
    "                \n",
    "        return window_ids, window_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.window_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_ids = torch.tensor(self.window_ids[idx], dtype=torch.int32, device=self.device)\n",
    "        label = torch.tensor(self.windows_labels[idx], dtype=torch.float32, device=self.device)\n",
    "        return window_ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d59e6e6-cfc8-4a40-ac56-1083cd41e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "train_texts, train_ends, train_files, train_keys = read_texts_from_json_files(DATA_FILES)\n",
    "val_texts, val_ends, val_files, val_keys = read_texts_from_json_files(VAL_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c126da23-5241-4175-93a3-05c6dd93128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(vocab_size=300, special_tokens=[\"[UNK]\", \"[PAD]\"])\n",
    "\n",
    "# Define the sequence of pre-tokenizers\n",
    "tokenizer.pre_tokenizer = Sequence([\n",
    "    Split(pattern=\"\\n\", behavior=\"isolated\"),\n",
    "    Split(pattern=Regex(r'\\w+|[^\\w\\t ]+'), behavior=\"removed\", invert=True), # Like the Whitespace() pre_tokenizer, but ignores newline \"\\n\" characters, as we want to tokenize these,\n",
    "    Punctuation()\n",
    "])\n",
    "\n",
    "tokenizer.train_from_iterator(train_texts, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553eab7f-e9ab-4732-847b-e4e162283951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare torch dataloaders\n",
    "\n",
    "train_dataset = TextDataset(train_texts, train_ends, tokenizer)\n",
    "val_dataset = TextDataset(val_texts, val_ends, tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e90809dc-eba6-422d-a075-0604e3e1bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size=64):\n",
    "        super(CNNModel, self).__init__()\n",
    "        kernel_size = 5\n",
    "        conv_out_channels = 6\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
    "        self.conv1d = nn.Conv1d(in_channels=embedding_size, out_channels=conv_out_channels, kernel_size=kernel_size)\n",
    "        self.fc1 = nn.Linear(((CONTEXT_WINDOW*2+1)-kernel_size+1)*conv_out_channels, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).permute(0, 2, 1)\n",
    "        x = self.conv1d(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        output = torch.sigmoid(x)\n",
    "        return output\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch, labels in dataloader:\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(batch)\n",
    "        \n",
    "        all_predictions.append(predictions)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    all_predictions = torch.cat(all_predictions)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    return all_predictions, all_labels\n",
    "\n",
    "def calculate_metrics(preds, targets):\n",
    "    # Ensure the predictions and targets are torch tensors\n",
    "    if not isinstance(preds, torch.Tensor):\n",
    "        preds = torch.tensor(preds)\n",
    "    if not isinstance(targets, torch.Tensor):\n",
    "        targets = torch.tensor(targets)\n",
    "\n",
    "    # Threshold predictions to binary values (assuming binary classification with threshold of 0.5)\n",
    "    preds = (preds >= 0.5).float()\n",
    "\n",
    "    # Calculate True Positives, False Positives, True Negatives, and False Negatives\n",
    "    TP = ((preds == 1) & (targets == 1)).sum().item()\n",
    "    FP = ((preds == 1) & (targets == 0)).sum().item()\n",
    "    TN = ((preds == 0) & (targets == 0)).sum().item()\n",
    "    FN = ((preds == 0) & (targets == 1)).sum().item()\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "    # Calculate Precision, Recall, and F1 Score\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Confusion Matrix\n",
    "    confusion_matrix = torch.tensor([[TN, FP], [FN, TP]])\n",
    "\n",
    "    return {\n",
    "        'True Positives': TP,\n",
    "        'False Positives': FP,\n",
    "        'True Negatives': TN,\n",
    "        'False Negatives': FN,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Confusion Matrix': confusion_matrix\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10bc59d2-2068-4d91-b617-5e327241fe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = CNNModel(vocab_size=tokenizer.get_vocab_size())\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddb46588-322b-4768-bad4-1790afedcef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/workspace/sandbox/legallm/notebooks/env/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val f1: 0.9277018633540374\n",
      "train f1: 0.9652982535722386\n",
      "Epoch: 2\n",
      "val f1: 0.9386763056213386\n",
      "train f1: 0.9783544845287323\n",
      "Epoch: 3\n",
      "val f1: 0.9407232509009568\n",
      "train f1: 0.9834442737668544\n",
      "Epoch: 4\n",
      "val f1: 0.9415863141524106\n",
      "train f1: 0.9861559101418662\n",
      "Epoch: 5\n",
      "val f1: 0.9449853943524831\n",
      "train f1: 0.987829441969985\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    model.train()\n",
    "    for batch, labels in train_dataloader:\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(batch)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(predictions, labels.view(-1, 1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_predictions, train_labels = predict(model, train_dataloader)\n",
    "        val_predictions, val_labels = predict(model, val_dataloader)\n",
    "        val_metrics = calculate_metrics(val_predictions.flatten(), val_labels)\n",
    "        train_metrics = calculate_metrics(train_predictions.flatten(), train_labels)\n",
    "        print(f\"val f1: {val_metrics[\"F1 Score\"]}\")\n",
    "        print(f\"train f1: {train_metrics[\"F1 Score\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f555cfd-d592-419c-bb55-a46301f1d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Investigation of Ensemble Efficacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05bbd78e-7160-4f35-8fdd-bad16176d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ensemble_model(criterion, num_epochs=5):\n",
    "    # Instantiate the model, define the loss function and the optimizer\n",
    "    model = CNNModel(vocab_size=tokenizer.get_vocab_size())\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch+1}\")\n",
    "        model.train()\n",
    "        for batch, labels in train_dataloader:\n",
    "            \n",
    "            # Forward pass\n",
    "            predictions = model(batch)\n",
    "    \n",
    "            # Calculate loss\n",
    "            loss = criterion(predictions, labels.view(-1, 1))\n",
    "    \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_predictions, train_labels = predict(model, train_dataloader)\n",
    "        val_predictions, val_labels = predict(model, val_dataloader)\n",
    "        val_metrics = calculate_metrics(val_predictions.flatten(), val_labels)\n",
    "        print(f\"val f1: {val_metrics[\"F1 Score\"]}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83c04be8-cfcb-4046-be1a-7705322ea17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "val f1: 0.9423932651834035\n",
      "Preparing model 1\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "val f1: 0.9380816478471276\n",
      "Preparing model 2\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "val f1: 0.9489248968024152\n",
      "Preparing model 3\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "val f1: 0.9406081625069672\n",
      "Preparing model 4\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "val f1: 0.9418877236273905\n"
     ]
    }
   ],
   "source": [
    "ensemble_models = []\n",
    "for i in range(5):\n",
    "    print(f\"Preparing model {i}\")\n",
    "    ensemble_models.append(\n",
    "        prepare_ensemble_model(criterion)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c831e3-9494-4ada-9fdf-bdf1839a04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(ensemble, dataloader):\n",
    "    ensembled_predictions = []\n",
    "    for model in ensemble:\n",
    "        pred, _ = predict(model, dataloader)\n",
    "        ensembled_predictions.append(pred)\n",
    "    return torch.stack(ensembled_predictions)\n",
    "\n",
    "ensembled_predictions = ensemble_predict(ensemble_models, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b65df57-10bc-4fdc-bf17-11eecf4129fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'True Positives': 7749,\n",
       " 'False Positives': 200,\n",
       " 'True Negatives': 18667,\n",
       " 'False Negatives': 544,\n",
       " 'Accuracy': 0.9726067746686303,\n",
       " 'Precision': 0.974839602465719,\n",
       " 'Recall': 0.9344025081393946,\n",
       " 'F1 Score': 0.9541928333949021,\n",
       " 'Confusion Matrix': tensor([[18667,   200],\n",
       "         [  544,  7749]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = calculate_metrics(ensembled_predictions.mean(axis=0).flatten(), val_labels)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fb19f70-de08-4d32-af3c-8590f151fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigation of ensemble uncertainty metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "988ff3a7-583f-4b1a-8366-114464acd77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = ((ensembled_predictions.mean(axis=0).flatten() > 0.5) == val_labels.type(torch.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7d8ab5b-cb87-45ae-a331-7ac11f2a70f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0059, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembled_predictions.var(axis=0).flatten()[correct_prediction].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "102f4e59-37c9-46c8-9095-fdaac210da4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0006, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembled_predictions.var(axis=0).flatten()[correct_prediction].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ebbb94b-8e08-4240-8b4a-88264e6fd3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0697, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembled_predictions.var(axis=0).flatten()[~correct_prediction].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9c3a4f3-eefc-4222-8464-61452ee229b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0040, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensembled_predictions.var(axis=0).flatten()[~correct_prediction].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67d393a1-4182-478c-8097-16c0f4ff56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_mask = ensembled_predictions.var(axis=0).flatten() > 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a197e34-22fe-462d-b62a-46553aa99993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1703)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertainty_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18761fbe-e52c-46aa-854a-a5242d7e776e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'True Positives': 7103,\n",
       " 'False Positives': 74,\n",
       " 'True Negatives': 18049,\n",
       " 'False Negatives': 231,\n",
       " 'Accuracy': 0.9880190124523707,\n",
       " 'Precision': 0.9896892852166643,\n",
       " 'Recall': 0.9685028633760567,\n",
       " 'F1 Score': 0.9789814623389153,\n",
       " 'Confusion Matrix': tensor([[18049,    74],\n",
       "         [  231,  7103]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = calculate_metrics(ensembled_predictions.mean(axis=0).flatten()[~uncertainty_mask], val_labels[~uncertainty_mask])\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labellm",
   "language": "python",
   "name": "labellm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
